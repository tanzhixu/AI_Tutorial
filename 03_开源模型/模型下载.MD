### 模型下载
#### 网页下载
在[本站](https://hf-mirror.com/)搜索，并在模型主页的Files and Version中下载文件。
####  使用huggingface-cli下载模型
```
huggingface-cli 是 Hugging Face 官方提供的命令行工具，自带完善的下载功能。

1. 安装依赖
pip install -U huggingface_hub
2. 设置环境变量
Linux
export HF_ENDPOINT=https://hf-mirror.com
Windows Powershell
$env:HF_ENDPOINT = "https://hf-mirror.com"
建议将上面这一行写入 ~/.bashrc。
3.1 下载模型
huggingface-cli download meta-llama/Meta-Llama-3-8B --include "original/*" --local-dir /mnt/mydisk/models/Meta-Llama-3-8B
huggingface-cli download --resume-download gpt2 --local-dir /mnt/mydisk/models/
3.2 下载数据集
huggingface-cli download --repo-type dataset --resume-download wikitext --local-dir wikitext
可以添加 --local-dir-use-symlinks False 参数禁用文件软链接，这样下载路径下所见即所得，详细解释请见上面提到的教程
```

#### 使用 hfd
```
hfd 是本站开发的 huggingface 专用下载工具，基于成熟工具 git+aria2，可以做到稳定下载不断线。

1. 下载hfd
wget https://hf-mirror.com/hfd/hfd.sh
chmod a+x hfd.sh
2. 设置环境变量
Linux
export HF_ENDPOINT=https://hf-mirror.com
Windows Powershell
$env:HF_ENDPOINT = "https://hf-mirror.com"
3.1 下载模型
./hfd.sh gpt2 --tool aria2c -x 4
3.2 下载数据集
./hfd.sh wikitext --dataset --tool aria2c -x 4
```

#### 使用环境变量（非侵入式）
非侵入式，能解决大部分情况。huggingface 工具链会获取HF_ENDPOINT环境变量来确定下载文件所用的网址，所以可以使用通过设置变量来解决。
```
HF_ENDPOINT=https://hf-mirror.com python your_script.py
```
Copy不过有些数据集有内置的下载脚本，那就需要手动改一下脚本内的地址来实现了
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:29:16.314764Z",
     "iopub.status.busy": "2024-04-18T08:29:16.314277Z",
     "iopub.status.idle": "2024-04-18T08:29:16.318740Z",
     "shell.execute_reply": "2024-04-18T08:29:16.317894Z",
     "shell.execute_reply.started": "2024-04-18T08:29:16.314734Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from contextlib import nullcontext\n",
    "import torch\n",
    "import tiktoken\n",
    "from model import Model \n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:00.002492Z",
     "iopub.status.busy": "2024-04-18T08:32:00.002008Z",
     "iopub.status.idle": "2024-04-18T08:32:00.008462Z",
     "shell.execute_reply": "2024-04-18T08:32:00.007658Z",
     "shell.execute_reply.started": "2024-04-18T08:32:00.002461Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffae4b52670>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_config_file(file_path):\n",
    "    # 创建 ConfigParser 对象\n",
    "    config = configparser.ConfigParser()\n",
    "    # 读取配置文件\n",
    "    config.read(file_path)\n",
    "    return config\n",
    "\n",
    "config_file_path = 'hyper-parameters.ini'\n",
    "config = read_config_file(config_file_path)\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = config.getint('Hyperparameters', 'batch_size')\n",
    "context_length = config.getint('Hyperparameters', 'context_length')\n",
    "max_iters = config.getint('Hyperparameters', 'max_iters')\n",
    "learning_rate = config.getfloat('Hyperparameters', 'learning_rate')\n",
    "eval_interval = config.getint('Hyperparameters', 'eval_interval')\n",
    "eval_iters = config.getfloat('Hyperparameters', 'eval_iters')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "TORCH_SEED = 1337\n",
    "torch.manual_seed(TORCH_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:03.210275Z",
     "iopub.status.busy": "2024-04-18T08:32:03.209800Z",
     "iopub.status.idle": "2024-04-18T08:32:05.026337Z",
     "shell.execute_reply": "2024-04-18T08:32:05.025449Z",
     "shell.execute_reply.started": "2024-04-18T08:32:03.210245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "with open('data/scifi.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:08.327745Z",
     "iopub.status.busy": "2024-04-18T08:32:08.327270Z",
     "iopub.status.idle": "2024-04-18T08:32:37.541662Z",
     "shell.execute_reply": "2024-04-18T08:32:37.540722Z",
     "shell.execute_reply.started": "2024-04-18T08:32:08.327716Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab = sorted(list(set(text)))\n",
    "vocab_size = max_token_value = len(vocab)\n",
    "char2idx = {c:i for i,c in enumerate(vocab)}\n",
    "idx2char = {i:c for i,c in enumerate(vocab)}\n",
    "encode = lambda x: [char2idx[c] for c in x]\n",
    "decode = lambda idxs: ''.join([idx2char[i] for i in idxs])\n",
    "tokenized_text = torch.tensor(encode(text), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:37.543403Z",
     "iopub.status.busy": "2024-04-18T08:32:37.543020Z",
     "iopub.status.idle": "2024-04-18T08:32:37.575188Z",
     "shell.execute_reply": "2024-04-18T08:32:37.574461Z",
     "shell.execute_reply.started": "2024-04-18T08:32:37.543368Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split train and validation set\n",
    "train_size = int(0.8 * len(tokenized_text))\n",
    "train_data = tokenized_text[:train_size]\n",
    "val_data = tokenized_text[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:40.153381Z",
     "iopub.status.busy": "2024-04-18T08:32:40.152882Z",
     "iopub.status.idle": "2024-04-18T08:32:40.585302Z",
     "shell.execute_reply": "2024-04-18T08:32:40.584424Z",
     "shell.execute_reply.started": "2024-04-18T08:32:40.153350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始化模型\n",
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:42.720583Z",
     "iopub.status.busy": "2024-04-18T08:32:42.720079Z",
     "iopub.status.idle": "2024-04-18T08:32:42.725739Z",
     "shell.execute_reply": "2024-04-18T08:32:42.724856Z",
     "shell.execute_reply.started": "2024-04-18T08:32:42.720547Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get input embedding batch\n",
    "def get_batch(split: str):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    idxs = torch.randint(low=0, high=len(data) - context_length, size=(batch_size,))\n",
    "    x = torch.stack([data[idx:idx + context_length] for idx in idxs]).to(device)\n",
    "    y = torch.stack([data[idx + 1:idx + context_length + 1] for idx in idxs]).to(device)\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:50.876906Z",
     "iopub.status.busy": "2024-04-18T08:32:50.876434Z",
     "iopub.status.idle": "2024-04-18T08:32:50.881788Z",
     "shell.execute_reply": "2024-04-18T08:32:50.881068Z",
     "shell.execute_reply.started": "2024-04-18T08:32:50.876877Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'valid']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            x_batch, y_batch = get_batch(split)\n",
    "            logits, loss = model(x_batch, y_batch)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T08:32:52.304555Z",
     "iopub.status.busy": "2024-04-18T08:32:52.304080Z",
     "iopub.status.idle": "2024-04-18T08:47:56.691840Z",
     "shell.execute_reply": "2024-04-18T08:47:56.691115Z",
     "shell.execute_reply.started": "2024-04-18T08:32:52.304526Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Training Loss: 11.714 Validation Loss: 11.68\n",
      "Step: 20 Training Loss: 10.127 Validation Loss: 10.14\n",
      "Step: 40 Training Loss: 8.399 Validation Loss: 8.405\n",
      "Step: 60 Training Loss: 7.151 Validation Loss: 7.188\n",
      "Step: 80 Training Loss: 6.796 Validation Loss: 6.75\n",
      "Step: 100 Training Loss: 6.653 Validation Loss: 6.64\n",
      "Step: 120 Training Loss: 6.635 Validation Loss: 6.732\n",
      "Step: 140 Training Loss: 6.553 Validation Loss: 6.532\n",
      "Step: 160 Training Loss: 6.455 Validation Loss: 6.516\n",
      "Step: 180 Training Loss: 6.472 Validation Loss: 6.456\n",
      "Step: 200 Training Loss: 6.495 Validation Loss: 6.356\n",
      "Step: 220 Training Loss: 6.403 Validation Loss: 6.499\n",
      "Step: 240 Training Loss: 6.382 Validation Loss: 6.256\n",
      "Step: 260 Training Loss: 6.169 Validation Loss: 6.329\n",
      "Step: 280 Training Loss: 6.268 Validation Loss: 6.208\n",
      "Step: 300 Training Loss: 6.187 Validation Loss: 6.175\n",
      "Step: 320 Training Loss: 6.207 Validation Loss: 6.196\n",
      "Step: 340 Training Loss: 6.263 Validation Loss: 6.141\n",
      "Step: 360 Training Loss: 6.156 Validation Loss: 6.212\n",
      "Step: 380 Training Loss: 6.143 Validation Loss: 6.166\n",
      "Step: 400 Training Loss: 6.049 Validation Loss: 5.949\n",
      "Step: 420 Training Loss: 5.967 Validation Loss: 6.047\n",
      "Step: 440 Training Loss: 6.052 Validation Loss: 5.968\n",
      "Step: 460 Training Loss: 6.025 Validation Loss: 6.068\n",
      "Step: 480 Training Loss: 5.966 Validation Loss: 5.996\n",
      "Step: 500 Training Loss: 6.047 Validation Loss: 5.989\n",
      "Step: 520 Training Loss: 5.895 Validation Loss: 6.048\n",
      "Step: 540 Training Loss: 5.946 Validation Loss: 5.989\n",
      "Step: 560 Training Loss: 5.972 Validation Loss: 5.907\n",
      "Step: 580 Training Loss: 5.86 Validation Loss: 5.929\n",
      "Step: 600 Training Loss: 5.862 Validation Loss: 5.778\n",
      "Step: 620 Training Loss: 5.807 Validation Loss: 5.929\n",
      "Step: 640 Training Loss: 5.75 Validation Loss: 5.867\n",
      "Step: 660 Training Loss: 5.766 Validation Loss: 5.722\n",
      "Step: 680 Training Loss: 5.787 Validation Loss: 5.783\n",
      "Step: 700 Training Loss: 5.824 Validation Loss: 5.838\n",
      "Step: 720 Training Loss: 5.925 Validation Loss: 5.718\n",
      "Step: 740 Training Loss: 5.838 Validation Loss: 5.697\n",
      "Step: 760 Training Loss: 5.742 Validation Loss: 5.752\n",
      "Step: 780 Training Loss: 5.727 Validation Loss: 5.792\n",
      "Step: 800 Training Loss: 5.691 Validation Loss: 5.837\n",
      "Step: 820 Training Loss: 5.69 Validation Loss: 5.75\n",
      "Step: 840 Training Loss: 5.756 Validation Loss: 5.715\n",
      "Step: 860 Training Loss: 5.66 Validation Loss: 5.725\n",
      "Step: 880 Training Loss: 5.644 Validation Loss: 5.639\n",
      "Step: 900 Training Loss: 5.669 Validation Loss: 5.652\n",
      "Step: 920 Training Loss: 5.727 Validation Loss: 5.66\n",
      "Step: 940 Training Loss: 5.69 Validation Loss: 5.602\n",
      "Step: 960 Training Loss: 5.627 Validation Loss: 5.714\n",
      "Step: 980 Training Loss: 5.676 Validation Loss: 5.58\n",
      "Step: 1000 Training Loss: 5.493 Validation Loss: 5.486\n",
      "Step: 1020 Training Loss: 5.54 Validation Loss: 5.545\n",
      "Step: 1040 Training Loss: 5.686 Validation Loss: 5.562\n",
      "Step: 1060 Training Loss: 5.586 Validation Loss: 5.575\n",
      "Step: 1080 Training Loss: 5.56 Validation Loss: 5.552\n",
      "Step: 1100 Training Loss: 5.561 Validation Loss: 5.588\n",
      "Step: 1120 Training Loss: 5.627 Validation Loss: 5.555\n",
      "Step: 1140 Training Loss: 5.629 Validation Loss: 5.559\n",
      "Step: 1160 Training Loss: 5.533 Validation Loss: 5.534\n",
      "Step: 1180 Training Loss: 5.434 Validation Loss: 5.5\n",
      "Step: 1200 Training Loss: 5.543 Validation Loss: 5.461\n",
      "Step: 1220 Training Loss: 5.5 Validation Loss: 5.535\n",
      "Step: 1240 Training Loss: 5.552 Validation Loss: 5.527\n",
      "Step: 1260 Training Loss: 5.546 Validation Loss: 5.505\n",
      "Step: 1280 Training Loss: 5.4 Validation Loss: 5.502\n",
      "Step: 1300 Training Loss: 5.517 Validation Loss: 5.479\n",
      "Step: 1320 Training Loss: 5.569 Validation Loss: 5.456\n",
      "Step: 1340 Training Loss: 5.453 Validation Loss: 5.53\n",
      "Step: 1360 Training Loss: 5.399 Validation Loss: 5.359\n",
      "Step: 1380 Training Loss: 5.387 Validation Loss: 5.404\n",
      "Step: 1400 Training Loss: 5.529 Validation Loss: 5.522\n",
      "Step: 1420 Training Loss: 5.403 Validation Loss: 5.38\n",
      "Step: 1440 Training Loss: 5.402 Validation Loss: 5.463\n",
      "Step: 1460 Training Loss: 5.478 Validation Loss: 5.48\n",
      "Step: 1480 Training Loss: 5.315 Validation Loss: 5.455\n",
      "Step: 1500 Training Loss: 5.289 Validation Loss: 5.473\n",
      "Step: 1520 Training Loss: 5.402 Validation Loss: 5.432\n",
      "Step: 1540 Training Loss: 5.507 Validation Loss: 5.354\n",
      "Step: 1560 Training Loss: 5.398 Validation Loss: 5.351\n",
      "Step: 1580 Training Loss: 5.294 Validation Loss: 5.408\n",
      "Step: 1600 Training Loss: 5.424 Validation Loss: 5.482\n",
      "Step: 1620 Training Loss: 5.345 Validation Loss: 5.403\n",
      "Step: 1640 Training Loss: 5.337 Validation Loss: 5.486\n",
      "Step: 1660 Training Loss: 5.348 Validation Loss: 5.326\n",
      "Step: 1680 Training Loss: 5.305 Validation Loss: 5.344\n",
      "Step: 1700 Training Loss: 5.358 Validation Loss: 5.445\n",
      "Step: 1720 Training Loss: 5.382 Validation Loss: 5.335\n",
      "Step: 1740 Training Loss: 5.363 Validation Loss: 5.421\n",
      "Step: 1760 Training Loss: 5.33 Validation Loss: 5.335\n",
      "Step: 1780 Training Loss: 5.245 Validation Loss: 5.392\n",
      "Step: 1800 Training Loss: 5.202 Validation Loss: 5.325\n",
      "Step: 1820 Training Loss: 5.382 Validation Loss: 5.342\n",
      "Step: 1840 Training Loss: 5.398 Validation Loss: 5.385\n",
      "Step: 1860 Training Loss: 5.413 Validation Loss: 5.312\n",
      "Step: 1880 Training Loss: 5.373 Validation Loss: 5.31\n",
      "Step: 1900 Training Loss: 5.383 Validation Loss: 5.341\n",
      "Step: 1920 Training Loss: 5.242 Validation Loss: 5.318\n",
      "Step: 1940 Training Loss: 5.281 Validation Loss: 5.227\n",
      "Step: 1960 Training Loss: 5.329 Validation Loss: 5.305\n",
      "Step: 1980 Training Loss: 5.3 Validation Loss: 5.159\n",
      "Step: 2000 Training Loss: 5.229 Validation Loss: 5.372\n",
      "Step: 2020 Training Loss: 5.302 Validation Loss: 5.388\n",
      "Step: 2040 Training Loss: 5.213 Validation Loss: 5.194\n",
      "Step: 2060 Training Loss: 5.218 Validation Loss: 5.269\n",
      "Step: 2080 Training Loss: 5.254 Validation Loss: 5.208\n",
      "Step: 2100 Training Loss: 5.244 Validation Loss: 5.309\n",
      "Step: 2120 Training Loss: 5.386 Validation Loss: 5.26\n",
      "Step: 2140 Training Loss: 5.221 Validation Loss: 5.248\n",
      "Step: 2160 Training Loss: 5.187 Validation Loss: 5.278\n",
      "Step: 2180 Training Loss: 5.363 Validation Loss: 5.167\n",
      "Step: 2200 Training Loss: 5.195 Validation Loss: 5.26\n",
      "Step: 2220 Training Loss: 5.296 Validation Loss: 5.338\n",
      "Step: 2240 Training Loss: 5.2 Validation Loss: 5.194\n",
      "Step: 2260 Training Loss: 5.325 Validation Loss: 5.271\n",
      "Step: 2280 Training Loss: 5.174 Validation Loss: 5.234\n",
      "Step: 2300 Training Loss: 5.227 Validation Loss: 5.189\n",
      "Step: 2320 Training Loss: 5.296 Validation Loss: 5.199\n",
      "Step: 2340 Training Loss: 5.197 Validation Loss: 5.255\n",
      "Step: 2360 Training Loss: 5.233 Validation Loss: 5.221\n",
      "Step: 2380 Training Loss: 5.321 Validation Loss: 5.242\n",
      "Step: 2400 Training Loss: 5.282 Validation Loss: 5.215\n",
      "Step: 2420 Training Loss: 5.214 Validation Loss: 5.213\n",
      "Step: 2440 Training Loss: 5.236 Validation Loss: 5.187\n",
      "Step: 2460 Training Loss: 5.191 Validation Loss: 5.177\n",
      "Step: 2480 Training Loss: 5.165 Validation Loss: 5.312\n",
      "Step: 2500 Training Loss: 5.106 Validation Loss: 5.201\n",
      "Step: 2520 Training Loss: 5.209 Validation Loss: 5.25\n",
      "Step: 2540 Training Loss: 5.16 Validation Loss: 5.197\n",
      "Step: 2560 Training Loss: 5.284 Validation Loss: 5.147\n",
      "Step: 2580 Training Loss: 5.183 Validation Loss: 5.322\n",
      "Step: 2600 Training Loss: 5.211 Validation Loss: 5.221\n",
      "Step: 2620 Training Loss: 5.162 Validation Loss: 5.207\n",
      "Step: 2640 Training Loss: 5.112 Validation Loss: 5.102\n",
      "Step: 2660 Training Loss: 5.187 Validation Loss: 5.18\n",
      "Step: 2680 Training Loss: 5.221 Validation Loss: 5.15\n",
      "Step: 2700 Training Loss: 5.231 Validation Loss: 5.197\n",
      "Step: 2720 Training Loss: 5.136 Validation Loss: 5.148\n",
      "Step: 2740 Training Loss: 5.173 Validation Loss: 5.179\n",
      "Step: 2760 Training Loss: 5.166 Validation Loss: 5.162\n",
      "Step: 2780 Training Loss: 5.27 Validation Loss: 5.24\n",
      "Step: 2800 Training Loss: 5.037 Validation Loss: 5.231\n",
      "Step: 2820 Training Loss: 5.174 Validation Loss: 5.091\n",
      "Step: 2840 Training Loss: 5.073 Validation Loss: 5.072\n",
      "Step: 2860 Training Loss: 5.139 Validation Loss: 5.0\n",
      "Step: 2880 Training Loss: 5.131 Validation Loss: 5.199\n",
      "Step: 2900 Training Loss: 5.05 Validation Loss: 5.248\n",
      "Step: 2920 Training Loss: 5.122 Validation Loss: 5.111\n",
      "Step: 2940 Training Loss: 5.113 Validation Loss: 5.304\n",
      "Step: 2960 Training Loss: 5.135 Validation Loss: 5.185\n",
      "Step: 2980 Training Loss: 5.167 Validation Loss: 5.258\n",
      "Step: 3000 Training Loss: 5.165 Validation Loss: 5.164\n",
      "Step: 3020 Training Loss: 5.069 Validation Loss: 5.189\n",
      "Step: 3040 Training Loss: 5.145 Validation Loss: 5.166\n",
      "Step: 3060 Training Loss: 5.026 Validation Loss: 5.162\n",
      "Step: 3080 Training Loss: 5.076 Validation Loss: 5.202\n",
      "Step: 3100 Training Loss: 5.12 Validation Loss: 5.095\n",
      "Step: 3120 Training Loss: 5.16 Validation Loss: 5.116\n",
      "Step: 3140 Training Loss: 5.178 Validation Loss: 5.152\n",
      "Step: 3160 Training Loss: 5.157 Validation Loss: 5.03\n",
      "Step: 3180 Training Loss: 5.08 Validation Loss: 5.082\n",
      "Step: 3200 Training Loss: 5.048 Validation Loss: 5.04\n",
      "Step: 3220 Training Loss: 5.017 Validation Loss: 5.024\n",
      "Step: 3240 Training Loss: 5.063 Validation Loss: 5.156\n",
      "Step: 3260 Training Loss: 5.151 Validation Loss: 5.123\n",
      "Step: 3280 Training Loss: 4.961 Validation Loss: 5.183\n",
      "Step: 3300 Training Loss: 5.054 Validation Loss: 5.034\n",
      "Step: 3320 Training Loss: 5.101 Validation Loss: 5.097\n",
      "Step: 3340 Training Loss: 5.103 Validation Loss: 5.021\n",
      "Step: 3360 Training Loss: 5.166 Validation Loss: 5.051\n",
      "Step: 3380 Training Loss: 5.091 Validation Loss: 5.135\n",
      "Step: 3400 Training Loss: 5.065 Validation Loss: 5.022\n",
      "Step: 3420 Training Loss: 4.966 Validation Loss: 4.997\n",
      "Step: 3440 Training Loss: 4.973 Validation Loss: 4.997\n",
      "Step: 3460 Training Loss: 4.982 Validation Loss: 5.067\n",
      "Step: 3480 Training Loss: 5.123 Validation Loss: 5.052\n",
      "Step: 3500 Training Loss: 5.081 Validation Loss: 5.114\n",
      "Step: 3520 Training Loss: 5.09 Validation Loss: 5.07\n",
      "Step: 3540 Training Loss: 5.057 Validation Loss: 5.133\n",
      "Step: 3560 Training Loss: 5.036 Validation Loss: 5.002\n",
      "Step: 3580 Training Loss: 5.098 Validation Loss: 5.071\n",
      "Step: 3600 Training Loss: 5.008 Validation Loss: 5.034\n",
      "Step: 3620 Training Loss: 4.962 Validation Loss: 4.975\n",
      "Step: 3640 Training Loss: 5.023 Validation Loss: 5.074\n",
      "Step: 3660 Training Loss: 5.024 Validation Loss: 5.097\n",
      "Step: 3680 Training Loss: 4.948 Validation Loss: 5.069\n",
      "Step: 3700 Training Loss: 4.984 Validation Loss: 4.941\n",
      "Step: 3720 Training Loss: 5.042 Validation Loss: 5.042\n",
      "Step: 3740 Training Loss: 5.1 Validation Loss: 5.089\n",
      "Step: 3760 Training Loss: 4.973 Validation Loss: 5.12\n",
      "Step: 3780 Training Loss: 5.076 Validation Loss: 5.168\n",
      "Step: 3800 Training Loss: 5.024 Validation Loss: 4.929\n",
      "Step: 3820 Training Loss: 4.918 Validation Loss: 4.999\n",
      "Step: 3840 Training Loss: 5.096 Validation Loss: 5.045\n",
      "Step: 3860 Training Loss: 5.096 Validation Loss: 5.066\n",
      "Step: 3880 Training Loss: 5.09 Validation Loss: 5.004\n",
      "Step: 3900 Training Loss: 4.983 Validation Loss: 4.995\n",
      "Step: 3920 Training Loss: 4.986 Validation Loss: 4.96\n",
      "Step: 3940 Training Loss: 4.987 Validation Loss: 5.08\n",
      "Step: 3960 Training Loss: 5.138 Validation Loss: 4.994\n",
      "Step: 3980 Training Loss: 4.861 Validation Loss: 5.14\n",
      "Step: 4000 Training Loss: 5.021 Validation Loss: 4.979\n",
      "Step: 4020 Training Loss: 4.962 Validation Loss: 5.121\n",
      "Step: 4040 Training Loss: 5.007 Validation Loss: 5.136\n",
      "Step: 4060 Training Loss: 5.092 Validation Loss: 5.026\n",
      "Step: 4080 Training Loss: 4.949 Validation Loss: 5.121\n",
      "Step: 4100 Training Loss: 4.962 Validation Loss: 5.016\n",
      "Step: 4120 Training Loss: 4.959 Validation Loss: 5.102\n",
      "Step: 4140 Training Loss: 4.968 Validation Loss: 5.093\n",
      "Step: 4160 Training Loss: 4.949 Validation Loss: 4.96\n",
      "Step: 4180 Training Loss: 4.994 Validation Loss: 5.025\n",
      "Step: 4200 Training Loss: 4.861 Validation Loss: 4.952\n",
      "Step: 4220 Training Loss: 4.952 Validation Loss: 5.08\n",
      "Step: 4240 Training Loss: 4.943 Validation Loss: 5.064\n",
      "Step: 4260 Training Loss: 5.014 Validation Loss: 5.029\n",
      "Step: 4280 Training Loss: 5.045 Validation Loss: 4.959\n",
      "Step: 4300 Training Loss: 4.979 Validation Loss: 4.948\n",
      "Step: 4320 Training Loss: 4.992 Validation Loss: 5.064\n",
      "Step: 4340 Training Loss: 4.953 Validation Loss: 5.011\n",
      "Step: 4360 Training Loss: 4.853 Validation Loss: 5.11\n",
      "Step: 4380 Training Loss: 4.863 Validation Loss: 5.022\n",
      "Step: 4400 Training Loss: 4.914 Validation Loss: 4.964\n",
      "Step: 4420 Training Loss: 4.868 Validation Loss: 4.946\n",
      "Step: 4440 Training Loss: 4.966 Validation Loss: 5.048\n",
      "Step: 4460 Training Loss: 4.803 Validation Loss: 4.983\n",
      "Step: 4480 Training Loss: 5.044 Validation Loss: 4.955\n",
      "Step: 4500 Training Loss: 4.972 Validation Loss: 4.952\n",
      "Step: 4520 Training Loss: 4.914 Validation Loss: 5.002\n",
      "Step: 4540 Training Loss: 4.959 Validation Loss: 4.904\n",
      "Step: 4560 Training Loss: 4.91 Validation Loss: 4.999\n",
      "Step: 4580 Training Loss: 4.893 Validation Loss: 4.868\n",
      "Step: 4600 Training Loss: 4.879 Validation Loss: 4.98\n",
      "Step: 4620 Training Loss: 4.959 Validation Loss: 5.065\n",
      "Step: 4640 Training Loss: 4.984 Validation Loss: 4.934\n",
      "Step: 4660 Training Loss: 4.987 Validation Loss: 4.949\n",
      "Step: 4680 Training Loss: 4.932 Validation Loss: 4.927\n",
      "Step: 4700 Training Loss: 4.942 Validation Loss: 4.919\n",
      "Step: 4720 Training Loss: 4.98 Validation Loss: 4.947\n",
      "Step: 4740 Training Loss: 4.975 Validation Loss: 4.93\n",
      "Step: 4760 Training Loss: 4.878 Validation Loss: 4.988\n",
      "Step: 4780 Training Loss: 4.935 Validation Loss: 4.862\n",
      "Step: 4800 Training Loss: 4.907 Validation Loss: 4.958\n",
      "Step: 4820 Training Loss: 4.986 Validation Loss: 4.93\n",
      "Step: 4840 Training Loss: 4.941 Validation Loss: 4.904\n",
      "Step: 4860 Training Loss: 5.018 Validation Loss: 4.892\n",
      "Step: 4880 Training Loss: 4.962 Validation Loss: 5.008\n",
      "Step: 4900 Training Loss: 4.914 Validation Loss: 4.982\n",
      "Step: 4920 Training Loss: 5.015 Validation Loss: 4.957\n",
      "Step: 4940 Training Loss: 5.032 Validation Loss: 4.91\n",
      "Step: 4960 Training Loss: 4.997 Validation Loss: 4.861\n",
      "Step: 4980 Training Loss: 4.902 Validation Loss: 4.906\n",
      "Step: 4999 Training Loss: 4.914 Validation Loss: 5.046\n"
     ]
    }
   ],
   "source": [
    "# Use AdamW optimizer\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=learning_rate)\n",
    "tracked_losses = list()\n",
    "for step in range(max_iters):\n",
    "    if step % eval_iters == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        tracked_losses.append(losses)\n",
    "        print('Step:', step, 'Training Loss:', round(losses['train'].item(), 3), 'Validation Loss:',\n",
    "              round(losses['valid'].item(), 3))\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-18T09:04:15.090087Z",
     "iopub.status.busy": "2024-04-18T09:04:15.089602Z",
     "iopub.status.idle": "2024-04-18T09:04:15.227113Z",
     "shell.execute_reply": "2024-04-18T09:04:15.226340Z",
     "shell.execute_reply.started": "2024-04-18T09:04:15.090057Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model state dictionary\n",
    "torch.save(model.state_dict(), 'model/model-ckpt.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
